{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Intrusion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will focus on the main purpose of the KDD data set, which is a sample data set for **the Ihird International Knowledge Discovery and Data Mining Tools Competition (KDD cup 99)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KDD cup 99 page describes the motivation of the competition as follows:\n",
    "> Software to detect network intrusions protects a computer network from unauthorized users, including perhaps insiders.  The intrusion detector learning task is to build a predictive model (i.e. a classifier) capable of distinguishing between \"bad\" connections, called intrusions or attacks, and \"good\" normal connections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification of the KDD cup 99 mainly targets four types of attacks:\n",
    "- **DOS**: denial-of-service, e.g. syn flood;\n",
    "- **R2L**: unauthorized access from a remote machine, e.g. guessing password;\n",
    "- **U2R**:  unauthorized access to local superuser (root) privileges, e.g., various \"buffer overflow\" attacks;\n",
    "- **probing**: surveillance and other probing, e.g., port scanning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the main target of the KDD cup 99 is **knowledge Discovery** and **Data Mining**, this project will not involve any training and prediction. We will simply use pyspark to explore some well-known rules to extract some useful information from the KDD 99 data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the KDD 99 Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use the reduced dataset (1 percent) provided for the KDD Cup 1999, containing nearly half million network interactions. The file is provided as a *Gzip* file in the local directory.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "data_file = \"file://\" + os.getcwd() + \"/../kddcup.data_1_percent.gz\"\n",
    "raw_data = sc.textFile(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have created an RDD from the data set. The RDD data sets are structured as the csv format, with each row (i.e., each line) containing the fields of a **network interaction**. The fields in the same row are separated with commas (,). According to <http://kdd.ics.uci.edu/databases/kddcup99/task.html>, each row in the RDD data set contains the following four type of fields:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Basic features of individual TCP connections:\n",
    " \n",
    "|feature name  |description                                                  | type       |\n",
    "|--------------|-------------------------------------------------------------|------------|\n",
    "|duration \t   |length (number of seconds) of the connection                 | continuous |\n",
    "|protocol_type |type of the protocol, e.g. tcp, udp, etc.                    | discrete   |\n",
    "|service \t   |network service on the destination, e.g., http, telnet, etc. | discrete   |\n",
    "|src_bytes \t   |number of data bytes from source to destination \t         | continuous |\n",
    "|dst_bytes \t   |number of data bytes from destination to source \t         | continuous |\n",
    "|flag \t       |normal or error status of the connection \t                 | discrete   | \n",
    "|land \t       |1 if connection is from/to the same host/port; 0 otherwise \t | discrete   |\n",
    "|wrong_fragment|number of \"wrong\" fragments \t                             | continuous |\n",
    "|urgent \t   |number of urgent packets \t                                 | continuous |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Content features within a connection suggested by domain knowledge:\n",
    " \n",
    "|feature name      |description                                                  | type       |\n",
    "|------------------|-------------------------------------------------------------|------------|\n",
    "|hot \t           |number of \"hot\" indicators\t                                 |continuous  |\n",
    "|num_failed_logins |number of failed login attempts \t                         |continuous  |\n",
    "|logged_in         |1 if successfully logged in; 0 otherwise \t                 |discrete    |\n",
    "|num_compromised   |number of \"compromised\" conditions \t                         |continuous  |\n",
    "|root_shell        |1 if root shell is obtained; 0 otherwise \t                 |discrete    |\n",
    "|su_attempted      |1 if `su root` command attempted; 0 otherwise \t             |discrete    |\n",
    "|num_root          |number of \"root\" accesses \t                                 |continuous  |\n",
    "|num_file_creations|number of file creation operations \t                         |continuous  |\n",
    "|num_shells        |number of shell prompts \t                                 |continuous  |\n",
    "|num_access_files  |number of operations on access control files \t             |continuous  |\n",
    "|num_outbound_cmds |number of outbound commands in an ftp session \t             |continuous  |\n",
    "|is_hot_login      |1 if the login belongs to the \"hot\" list; 0 otherwise        |discrete    |\n",
    "|is_guest_login    |1 if the login is a \"guest\" login; 0 otherwise               |discrete    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Traffic features computed using a two-second time window:\n",
    " \n",
    "|feature name  |description                                                  | type       |\n",
    "|--------------|-------------------------------------------------------------|------------|\n",
    "|count         |number of connections to the same host as the current connection in the past two seconds|continuous|\n",
    "|-             |Note: The following  features refer to these same-host connections.|      |\t\n",
    "|serror_rate   |% of connections that have \"SYN\" errors \t                 |continuous  |\n",
    "|rerror_rate   |% of connections that have \"REJ\" errors \t                 |continuous  |\n",
    "|same_srv_rate |% of connections to the same service \t                     |continuous  |\n",
    "|diff_srv_rate  |% of connections to different services                      |continuous  |\n",
    "|srv_count      |number of connections to the same service as the current connection in the past two seconds|continuous |\n",
    "|-              |Note: The following features refer to these same-service connections.|    |\t\n",
    "|srv_serror_rate|% of connections that have \"SYN\" errors                     |continuous  |\n",
    "|srv_rerror_rate|% of connections that have \"REJ\" errors                     |continuous  |\n",
    "|srv_diff_host_rate|% of connections to different hosts                      |continuous  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Tags**: classification of network interactions. This field shows the classification of the attack factor for each interactions. Possible values of tags are: back, buffer_overflow, ftp_write, guess_passwd, imap, ipsweep, land, loadmodule, multihop, neptune, nmap, normal, perl, phf, pod, portsweep, rootkit, satan, smurf, spy, teardrop, warezclient, warezmaster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, based on the data set, please list the top 10 attack factors (i.e., tags that are **not** \"normal\") and print in a readable format. Note: You must use RDDs to implement your algorithm. Processing the data locally without RDDs is not acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smurf.: counts = 28219\n",
      "neptune.: counts = 10704\n",
      "back.: counts = 195\n",
      "satan.: counts = 161\n",
      "ipsweep.: counts = 134\n",
      "warezclient.: counts = 103\n",
      "teardrop.: counts = 92\n",
      "portsweep.: counts = 85\n",
      "pod.: counts = 28\n",
      "nmap.: counts = 24\n",
      "Evaluation has taken 0.505 secs\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t0 = time()\n",
    "\n",
    "csv_data = raw_data.map(lambda x: x.split(\",\"))\n",
    "\n",
    "key_value_data = csv_data.map(lambda x: (x[41],x))\n",
    "\n",
    "# First RDD:  normal_interactions = interaction with tag = \"normal.\"\n",
    "normal_interactions = key_value_data.filter(lambda x: x[0] == \"normal.\")\n",
    "\n",
    "# Second RDD: attack_interactions = interaction with tag != \"normal.\"\n",
    "attack_interactions = key_value_data.filter(lambda x:x[0]!=\"normal.\")\n",
    "\n",
    "# third RDD:  attack_tag_counts = interaction count of each tag which is not \"normal\".\n",
    "attack_tag_counts = attack_interactions.mapValues(lambda x: 1).reduceByKey(lambda x, y: x+y)\n",
    "\n",
    "# fourth RDD: attack_tag_counts_sorted = sorted list of tags with their interaction counts.\n",
    "attack_tag_counts_sorted = attack_tag_counts.sortByKey()\n",
    "\n",
    "# result:     attack_tag_counts_top10 = top 10 attack tags and their interaction counts.\n",
    "attack_tag_counts_top10 = attack_tag_counts_sorted.takeOrdered(10, key=lambda x: -x[1])\n",
    "\n",
    "tt = time() - t0\n",
    "\n",
    "for (tag, count) in attack_tag_counts_top10:\n",
    "    print(tag + \": counts = \" + str(count))\n",
    "    \n",
    "print(\"Evaluation has taken {} secs\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Denial of Service (DDOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KDD 99 data set has defined six primary types of DOS attacks: **back**, **land**, **neptune**, **pod**, **smurf**, **teardrop**. Without further details of these DOS attacks, can you identified the attacks which are **most distributed**, as well as the attacks which are **most correlated with SYN errors**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, filter the network interactions in the raw data to contain only these six types of DOS attacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod.: counts = 28\n",
      "back.: counts = 195\n",
      "teardrop.: counts = 92\n",
      "land.: counts = 3\n",
      "neptune.: counts = 10704\n",
      "smurf.: counts = 28219\n",
      "Filtering DOS attacks has taken 0.514 secs\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Filter the network interactions to include only DOS attacks\n",
    "dos_attack_data = csv_data.filter(lambda x: x[41] == \"back.\" or x[41] == \"land.\" or x[41] == \"neptune.\" or x[41] == \"pod.\" or x[41] == \"smurf.\" or x[41] == \"teardrop.\")\n",
    "dos_attack_count_data = dos_attack_data.map(lambda x: (x[41],x))\n",
    "# Calculate the count of DOS interactions for each tag\n",
    "dos_attack_counts = dos_attack_count_data.mapValues(lambda x: 1).reduceByKey(lambda x, y: x+y).collect()\n",
    "\n",
    "tt = time() - t0\n",
    "\n",
    "for (tag, count) in dos_attack_counts:\n",
    "    print(tag + \": counts = \" + str(count))\n",
    "\n",
    "print(\"Filtering DOS attacks has taken {} secs\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, sort the DOS attacks to show, from the highest to the lowest, **the average numbers of connections** within the last 2 seconds (in regards to each host) involved in each DOS attack. Hint: use the mean values of the field `count` to determine the **most distributed** DOS attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smurf.: degree = 507.03696091286014\n",
      "neptune.: degree = 188.18890134529147\n",
      "teardrop.: degree = 65.52173913043478\n",
      "back.: degree = 3.2\n",
      "pod.: degree = 3.0\n",
      "land.: degree = 1.0\n",
      "Sorting DOS attacks by degree of distribution has taken 0.535 secs\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Calculate the mean values of distribution degrees (# of connections involved with the interaction)\n",
    "# ...\n",
    "dos_attack_counts = dos_attack_data.map(lambda x: (x[41],float(x[22])))\n",
    "\n",
    "sum_counts = dos_attack_counts.combineByKey(\n",
    "(lambda x: (x, 1)), \n",
    "(lambda c, v: (c[0]+v, c[1]+1)), \n",
    "(lambda c1, c2: (c1[0]+c2[0], c1[1]+c2[1]))\n",
    ")\n",
    "\n",
    "\n",
    "dos_attack_degrees = sum_counts.map(lambda kv: (kv[0],kv[1][0]/kv[1][1]))\n",
    "\n",
    "sorted_dos_attack_degrees = dos_attack_degrees.sortBy(lambda x: -x[1]).collect()\n",
    "\n",
    "tt = time() - t0\n",
    "\n",
    "for (tag, degree) in sorted_dos_attack_degrees:\n",
    "    print(tag + \": degree = \" + str(degree))\n",
    "\n",
    "print(\"Sorting DOS attacks by degree of distribution has taken {} secs\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, sort the DOS attacks show, from the highest to the lowest, **the average numbers of SYN errors** within the last 2 seconds (in regards to each host) involved in each DOS attack. Hint: approximate the numbers of SYN errors by multiplying `count` with `serror_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neptune.: degree = 152.90577354260088\n",
      "teardrop.: degree = 15.262826086956522\n",
      "land.: degree = 1.0\n",
      "back.: degree = 0.03076923076923077\n",
      "pod.: degree = 0.0\n",
      "smurf.: degree = 0.0\n",
      "Sorting DOS attacks by correlation with SYN flooding has taken 0.558 secs\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Calculate the average numbers of connections with SYN errors (# of connections involved with the interaction)\n",
    "# ...\n",
    "\n",
    "dos_attack_syn = dos_attack_data.map(lambda x: (x[41],float(x[24])*float(x[22])))\n",
    "\n",
    "sum_counts = dos_attack_syn.combineByKey(\n",
    "(lambda x: (x, 1)), \n",
    "(lambda c, v: (c[0]+v, c[1]+1)), \n",
    "(lambda c1, c2: (c1[0]+c2[0], c1[1]+c2[1]))\n",
    ")\n",
    "\n",
    "\n",
    "dos_attack_serror = sum_counts.map(lambda kv: (kv[0],kv[1][0]/kv[1][1]))\n",
    "\n",
    "# sorted_dos_attack_syn_error_counts = ...\n",
    "sorted_dos_attack_syn_error_counts = dos_attack_serror.sortBy(lambda x: -x[1]).collect()\n",
    "\n",
    "tt = time() - t0\n",
    "\n",
    "for (tag, count) in sorted_dos_attack_syn_error_counts:\n",
    "    print(tag + \": degree = \" + str(count))\n",
    "\n",
    "print(\"Sorting DOS attacks by correlation with SYN flooding has taken {} secs\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brute-force Login Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brute-force login attack relies on the attacker continuously re-attempting failed login to a host until being able to log into the host and eventually to perform `su` to become the root user. A host often has defense mechanisms such as ASLR (Address Space Layout Randomization) to reduce the probability for an attack to successfully perform `su` following successful login."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will calculate the **the average number of failed login attempt** before successful login (i.e., `logged_in == 1`), and **the average number of failed login attempt** before successful `su` to gain the root shell (i.e., `root_shell == 1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of attempts before successful login: 0.0\n",
      "Average number of attempts before successful su: 0.0\n",
      "Calculating the difficulty of brute-force login attacks has taken 0.672 secs\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Calculate the average numbers of failed login attempt before successful login\n",
    "logged_in = csv_data.filter(lambda x: x[11]=='1')\n",
    "\n",
    "failed_login = logged_in.map(lambda x: float(x[10]))\n",
    "\n",
    "failed_login_sum_count = failed_login.aggregate(\n",
    "    (0,0), # the initial value\n",
    "    (lambda acc, value: (acc[0] + value, acc[1] + 1)), # combine value with acc\n",
    "    (lambda acc1, acc2: (acc1[0] + acc2[0], acc1[1] + acc2[1])) # combine accumulators\n",
    ")\n",
    "\n",
    "    \n",
    "# average_attempt_before_login = ...\n",
    "average_attempt_before_login = round(failed_login_sum_count[0]/float(failed_login_sum_count[1]),3)\n",
    "\n",
    "# Calculate the average numbers of failed login attempt before successful `su` to gain the root shell\n",
    "\n",
    "# average_attempt_before_su = ...\n",
    "root_shell = csv_data.filter(lambda x: x[13]=='1')\n",
    "\n",
    "failed_su_attempts = logged_in.map(lambda x: float(x[10]))\n",
    "\n",
    "failed_su_sum_count = failed_su_attempts.aggregate(\n",
    "    (0,0), # the initial value\n",
    "    (lambda acc, value: (acc[0] + value, acc[1] + 1)), # combine value with acc\n",
    "    (lambda acc1, acc2: (acc1[0] + acc2[0], acc1[1] + acc2[1])) # combine accumulators\n",
    ")\n",
    "tt = time() - t0\n",
    "\n",
    "average_attempt_before_su = round(failed_su_sum_count[0]/float(failed_su_sum_count[1]),3)\n",
    "print(\"Average number of attempts before successful login: {}\".format(average_attempt_before_login))\n",
    "print(\"Average number of attempts before successful su: {}\".format(average_attempt_before_su))\n",
    "\n",
    "print(\"Calculating the difficulty of brute-force login attacks has taken {} secs\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
